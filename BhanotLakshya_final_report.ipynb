{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ***Introduction***\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "L6w8e2Mv2UFM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "This project examines a dataset that captures various aspects of student performance, providing a comprehensive view of factors influencing academic outcomes. The dataset encompasses both numerical and categorical variables, shedding light on students' academic behaviors, family backgrounds, and personal lifestyles. Key features include study time, the number of past failures, parental education levels, and extracurricular habits such as alcohol consumption and social activities. Together, these variables offer a multidimensional understanding of the elements affecting a student's final grade (G3).\n",
        "\n",
        "The central objective of this analysis is to develop a predictive model that accurately estimates students' final grades based on the provided features. This task is critical because it not only identifies factors contributing to academic success but also enables targeted interventions. Predictive insights can help educators allocate resources effectively, guide parental involvement, and tailor student-specific strategies for improvement. By focusing on measurable and actionable factors, the project bridges the gap between data-driven insights and practical application in educational contexts.\n",
        "\n",
        "Understanding what drives student performance is more relevant today than ever. With increasing pressure on students to excel academically, educators and policymakers need evidence-based strategies to address disparities and improve outcomes. This predictive task is not just about identifying high-performing students; it’s about uncovering patterns and predictors that can inform targeted support for struggling learners. By highlighting factors such as family background, academic habits, and social behaviors, the analysis provides a foundation for developing tailored interventions that address students' specific needs.\n",
        "\n",
        "The task also emphasizes equity in education, as it considers the diverse range of factors that influence performance. For example, socioeconomic conditions reflected in parental education levels and support systems may reveal systemic barriers that need to be addressed. Furthermore, the model’s ability to predict outcomes from multifaceted data ensures that decisions are based on robust evidence rather than assumptions. This relevance makes the study pivotal for educational institutions, policymakers, and communities aiming to enhance student success at scale.\n",
        "\n",
        "Preliminary analysis highlighted that certain factors, such as study time, prior academic failures, and parental education, are strongly correlated with student outcomes. Conversely, lifestyle factors like alcohol consumption or socializing frequency appear to have less influence. The modeling efforts revealed that features like the number of past failures, school absences, and study time are the strongest predictors of performance. By leveraging machine learning models, the project provides actionable insights into which areas deserve focus, enabling impactful strategies to improve academic results.\n",
        "\n",
        "This report will now delve deeper into the data's structure, the methodologies employed, and the results of the analysis, concluding with insights into how these findings can guide future educational practices."
      ],
      "metadata": {
        "id": "nvEwMxS43ooz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***The Dataset***"
      ],
      "metadata": {
        "id": "0KVJi5Un4zFW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "The dataset utilized for this project, titled \"Student Performance,\" originates from two Portuguese secondary schools and was collected by Paulo Cortez and Alice Silva. This dataset is publicly available on the UCI Machine Learning Repository and is frequently used in educational research due to its breadth of information about student demographics, social environments, and academic performance. The dataset consists of 649 instances and 30 features, which provide a holistic view of the factors influencing student grades. These features were gathered using a combination of school records and student questionnaires, making it a reliable source for analysis.\n",
        "\n",
        "The data is a blend of numerical and categorical variables, capturing a wide range of attributes. Numerical features include age, study time, number of absences, and parental education levels, while categorical features detail variables such as school attended, guardian relationship, and students’ access to internet or additional educational support. The target variable, G3, represents students' final grades for the third period and is measured on a scale from 0 to 20. This grade acts as the dependent variable in this project, with the goal of building predictive models to estimate it using the available independent variables.\n",
        "\n",
        "In the analysis, a conscious decision was made to exclude the features G1 and G2, which represent first- and second-period grades, respectively. These features are known to be highly correlated with G3 since they directly measure similar academic outcomes at earlier stages of the school year. While including these variables would likely improve model accuracy, it would do so at the expense of practical relevance. The aim of this project is to explore external factors—such as socioeconomic status, study habits, and family support—that influence academic performance. Using G1 and G2 could overshadow these broader insights by allowing the model to rely heavily on prior grades, which are not always available in real-world applications where predictive tools are often used to intervene early in a student's academic journey.\n",
        "\n",
        "The dataset has no missing values, ensuring the integrity of the analysis. Key numerical variables such as age and study time exhibit a range that aligns with expectations for secondary school students, with the average age being approximately 16.7 years and most students reporting less than 5 hours of weekly study time. Similarly, categorical variables provide meaningful distinctions between different groups of students, such as those living in urban versus rural areas or attending one of the two participating schools, Gabriel Pereira (GP) or Mousinho da Silveira (MS).\n",
        "\n",
        "By excluding redundant academic metrics like G1 and G2 and focusing on external factors, this analysis emphasizes the broader influences on student performance. This approach not only aligns with practical applications of predictive modeling in education but also enhances the potential for actionable insights to support educational planning and interventions. The dataset’s comprehensive scope and multivariate structure make it a robust foundation for understanding the interplay between student backgrounds, behaviors, and academic outcomes."
      ],
      "metadata": {
        "id": "5-JPfAW154YY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Exploring the Data***"
      ],
      "metadata": {
        "id": "dAaLPgFi6hFM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Numerical Features Analysis\n",
        "\n",
        "The numerical features in the dataset include variables like age, parental education levels, study time, absences, and various behavioral metrics. Each is critical in understanding how personal, familial, and behavioral attributes impact students’ academic performance.\n",
        "\n",
        "**Student Age**: The age variable ranges from 15 to 22 years, with a mean of 16.74 years and a standard deviation of 1.22. Most students fall in the 15-18 age bracket, indicating that the dataset primarily represents students in the early to middle stages of high school. The left-skewed distribution suggests relatively fewer older students, potentially due to grade retention or dropout.\n",
        "\n",
        "**Parental Education Levels (Medu, Fedu)**:\n",
        "  Both Medu (mother’s education level) and Fedu (father’s education level) are coded from 0 (no education) to 4 (higher education). The mean values for Medu and Fedu are approximately 2.51 and 2.51, respectively, indicating that secondary education is the predominant level among parents.\n",
        "   \n",
        "**Study Time**: Weekly study time (studytime) ranges from 1 (less than 2 hours) to 4 (more than 10 hours), with a mean of 1.93. This implies that most students dedicate 2-5 hours to studying weekly, suggesting moderate academic effort. S\n",
        "\n",
        "**School Absences**: Absences vary significantly, ranging from 0 to 32 days, with a mean of 3.65 and a standard deviation of 4.64. The highly right-skewed distribution shows that most students have minimal absences, but a small fraction report extreme absenteeism. These outliers are crucial as they represent behavioral tendencies that might impact academic success.\n",
        "\n",
        "**Failures**: The number of past class failures (failures) ranges from 0 to 3, with a mean of 0.22. Most students have not experienced failures, but for those who have, the correlation with G3 is strongly negative (-0.39), suggesting a significant impact of prior academic struggles on final performance.\n",
        "\n",
        "**Behavioral Features**:\n",
        "  Alcohol Consumption (Dalc, Walc): Alcohol consumption is measured on a scale of 1 to 5. Workday consumption (Dalc) has a mean of 1.50, while weekend consumption (Walc) is slightly higher, at 2.28. The low overall means indicate responsible behavior among most students, but some exhibit higher levels of consumption, which may influence academic outcomes.\n",
        "  Free Time and Social Activities: Features such as freetime (free time after school) and goout (frequency of going out with friends) have mean values of ~3, indicating moderate levels of both. These variables reflect lifestyle choices that could indirectly influence academic performance.\n",
        "\n",
        "\n",
        "#### Target Variable (G3) Analysis\n",
        "\n",
        "The target variable, G3 (final grade), ranges from 0 to 20, with a mean of 11 and a standard deviation of 3.23. The distribution is slightly left-skewed, with the following notable patterns:\n",
        "\n",
        "Approximately 25% of students scored below 10, and 25% scored above 14, suggesting a reasonable spread of academic performance.\n",
        "\n",
        "Zero scores (failures) are present, likely representing students who failed their final assessments. These cases require closer scrutiny to identify contributing factors.\n",
        "\n",
        "A histogram of G3 demonstrates a concentration of grades around the lower-middle range, with a long tail extending toward higher grades. The spread underscores the variability in performance and the potential influence of various factors captured in the dataset.\n",
        "\n",
        "\n",
        "\n",
        "#### Correlation Analysis\n",
        "\n",
        "\n",
        "Feature-to-Feature Correlations:\n",
        "A strong positive correlation (0.65) is observed between mother's education level and father's education level, reflecting the possibility of similar educational backgrounds within families. Weekend alcohol consumption (Walc) and workday alcohol consumption (Dalc) are positively correlated (0.62), suggesting that students who consume alcohol on weekends are also likely to do so on weekdays. Interestingly, study time exhibits no strong correlation with other features, except G3, indicating its independence as a driver of academic success.\n",
        "\n",
        "Final Grade (G3) and Other Features:\n",
        "A moderately positive correlation of 0.25 is observed between weekly study time and G3, suggesting that increased time dedicated to studying positively impacts academic performance. This aligns with the expectation that structured study efforts contribute to better outcomes. Mother's education level (correlation 0.24) and Father's education level (correlation 0.21) also show positive relationships with G3. This indicates that higher parental education is associated with improved academic performance, potentially reflecting a supportive and informed home environment.Meanwhile, a moderately negative correlation of -0.39 exists between number of past class failures and G3, showing that students who have failed classes in the past tend to achieve lower grades overall. Finally, features like free time after school, quality of family relationships, and current health status have very low correlations (close to 0) with G3, implying limited direct influence on academic outcomes.\n",
        "\n",
        "\n",
        "\n",
        "#### Categorical Features\n",
        "Categorical features, such as school, sex, address, and guardian, were also analyzed to understand their distributions:\n",
        "- **School**: Two schools are represented, GP and MS, with GP accounting for the majority of students. Differences in school policies or resources may partially explain variability in outcomes.\n",
        "- **Guardian**: The guardian variable shows a predominance of “mother” as the primary caregiver, followed by “father” and “other.”\n",
        "- **Address and Family Support**: Urban students (U) outnumber rural students (R), and students receiving family support (famsup) show slightly better academic performance.\n",
        "\n",
        "\n",
        "#### Outlier Analysis\n",
        "\n",
        "Box plots for numerical variables reveal outliers in several features, such as absences, failures, and age:\n",
        "\n",
        "Extreme absenteeism (e.g., students with 25+ absences) was retained as these cases provide insights into the relationship between absenteeism and academic struggles.\n",
        "\n",
        "Students with 3 prior failures represent an important subset for intervention strategies, given their consistent association with lower G3 scores.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "OmASph_o8NkV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***The Models***"
      ],
      "metadata": {
        "id": "0S9f5OB10WNi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Baseline Model\n",
        "I started with a baseline model to establish a reference point for evaluating future models. This model predicted the average of the target variable (y_train.mean) for all instances, resulting in a **Mean Squared Error (MSE)** of **10.0653**. While simplistic, this gave me a clear benchmark to assess whether the more complex models added any real predictive value. If any subsequent model fails to outperform this baseline, it would indicate that the model isn’t leveraging the features effectively. This step was necessary to gauge the usefulness of more advanced methods.\n",
        "\n",
        "\n",
        "\n",
        "#### Linear Regression\n",
        "The next step was to test linear regression, a simple and interpretable model. Before training, I ensured proper preprocessing by scaling the numerical features with StandardScaler and encoding categorical features using OneHotEncoder. Linear regression assumes a strict linear relationship between the features and the target variable, so it was a logical starting point to capture overall trends.\n",
        "\n",
        "The results showed a **train MSE of 6.4476** and a **test MSE of 8.1898**, both significantly better than the baseline. Thus, linear regression effectively captured broad patterns in the data but struggled to generalize perfectly to the test set, as seen from the higher test error. This hinted at potential underfitting due to the model’s linear constraints. These results made me consider trying non-linear models to capture more complex feature interactions.\n",
        "\n",
        "\n",
        "\n",
        "#### K-Nearest Neighbors (KNN)\n",
        "After linear regression, I decided to try KNN since it’s a non-parametric algorithm capable of capturing non-linear relationships. Using grid search, I tuned the n_neighbors hyperparameter, testing a range of values to identify the optimal configuration. I found that **11 neighbors** yielded the best performance, resulting in a **train MSE of 6.6966** and a **test MSE of 8.7810**.\n",
        "\n",
        "While KNN was flexible and did capture local patterns, the slightly higher test MSE suggested it overfit the training data to some extent. This could be attributed to KNN’s sensitivity to noise and outliers, as well as its reliance on local proximity. Though it performed better than the baseline, its generalization to unseen data wasn’t ideal. Based on these findings, I concluded that KNN provided some value but wasn’t robust enough for this dataset. This reinforced my decision to try tree-based models, which are more resilient to noise and better suited for handling mixed data types.\n",
        "\n",
        "\n",
        "\n",
        "#### Random Forest\n",
        "Finally, I implemented a Random Forest model, an ensemble learning method that combines multiple decision trees to improve performance and reduce overfitting. Using grid search, I tuned several hyperparameters, including the number of estimators, the maximum depth of trees, and the minimum number of samples for splits and leaves. The best configuration turned out to be:\n",
        "\n",
        "- **n_estimators**: 200  \n",
        "- **max_depth**: 5  \n",
        "- **min_samples_split**: 2  \n",
        "- **min_samples_leaf**: 1  \n",
        "\n",
        "The results were impressive, with a **train MSE of 4.4641** and a **test MSE of 7.0844**, making Random Forest the best-performing model so far. The Random Forest’s ability to handle non-linear interactions and mixed feature types showed clear advantages. It outperformed both linear regression and KNN, indicating that it could capture complex patterns in the data without overfitting. Given the strong performance of Random Forest, it became the most promising model for this dataset. I also examined feature importances from the Random Forest to identify which variables were contributing the most to predictions.\n",
        "\n",
        "\n",
        "\n",
        "### Results and Interpretation\n",
        "\n",
        "#### Comparing Models\n",
        "Here’s a summary of the models and how they performed:\n",
        "1. **Baseline Model**: The MSE of **10.0653** set the benchmark for comparison.\n",
        "2. **Linear Regression**: The model significantly reduced error to **8.1898** on the test set, capturing broad trends but showing signs of underfitting.\n",
        "3. **KNN**: With a test MSE of **8.7810**, KNN provided some insights but struggled with generalization due to its sensitivity to local noise.\n",
        "4. **Random Forest**: By far the best performer, this model achieved a test MSE of **7.0844**, indicating its ability to capture non-linear interactions and complex patterns effectively.\n",
        "\n",
        "#### Insights from Feature Importance\n",
        "Using the Random Forest’s feature importance metrics, I identified the following key contributors to student performance:\n",
        "- **Failures**: This was the most critical feature, reinforcing the idea that past academic struggles strongly influence future performance. Students with more failures had lower grades, highlighting the need for early intervention.\n",
        "- **Absences**: Attendance was another major factor, showing that students who missed more classes were at a significant disadvantage academically.\n",
        "- **School_MS**: This feature indicated potential differences between schools, suggesting that institutional factors like resources or teaching quality might play a role in student outcomes.\n",
        "- **Dalc and Walc (Alcohol Consumption)**: Both weekday and weekend alcohol consumption had negative impacts on grades, underscoring the importance of addressing lifestyle factors in educational settings.\n",
        "- **Parental Education (Fedu and Medu)**: Higher levels of parental education correlated with better student performance, suggesting that parental support and background significantly influence academic success.\n",
        "\n",
        "\n",
        "The results confirmed that combining different modeling approaches helps uncover valuable insights. Linear regression provided a baseline understanding of trends, while KNN highlighted local patterns, and Random Forest captured complex feature interactions. The importance of variables like failures and absences suggested actionable areas for intervention, such as providing targeted support for struggling students and addressing absenteeism.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gRhzRfsn0dwy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Conclusion and Next Steps***"
      ],
      "metadata": {
        "id": "lmHI-iJf3Z3E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conclusion\n",
        "\n",
        "This entire analysis was about understanding what factors impact student performance and figuring out how well we could predict their final grades using different models. Starting with the baseline model, I got a sense of how much error was present without any sophisticated modeling. The baseline MSE was pretty high at **10.0653**, which made it clear that there was room for improvement.\n",
        "\n",
        "Linear Regression came next. It captured some of the relationships between features and grades, but the test MSE was still **8.1898**, so it struggled with non-linear patterns. That’s when KNN came in. After tuning the hyperparameters, I found that setting **k=11** gave the best results, lowering the test MSE to **7.8010**. KNN worked better because it used localized patterns in the data, but it still wasn’t perfect.\n",
        "\n",
        "Finally, the Random Forest model was tested. With careful tuning, it delivered the best performance, with a test MSE of **7.0844**. This was because Random Forest can handle non-linear relationships and complex feature interactions much better than the other models. What stood out throughout the modeling was how strongly **failures** and **absences** influenced final grades. These two features consistently had the most impact, which wasn’t surprising but definitely reinforced how critical they are. While Random Forest performed the best, there’s always room to refine it. Exploring additional ensemble models like Gradient Boosting or XGBoost might push the performance even further. Plus, running the models on a more diverse dataset would help confirm how generalizable these results are.\n",
        "\n",
        "\n",
        "Overall, the models gave valuable insights. While Random Forest performed best, each method added something to my understanding of the data. The results clearly showed that addressing key factors like absences and past failures could make a meaningful difference in student outcomes.The next step would be to dive deeper into why these are happening. For example, looking into what causes students to fail—whether it’s lack of support, personal struggles, or something else—and addressing that directly through targeted interventions. Similarly, absences could be tackled with things like better attendance tracking and student engagement programs.\n",
        "\n",
        "   \n",
        "\n",
        " The real goal of studies like these is to make these insights practical. A good next step would be creating a dashboard for educators that flags high-risk students based on the key factors like absences or low study time. This way, teachers and counselors could step in early and provide support where it’s needed most. Using the insights from the models, schools could try implementing specific programs—like tutoring sessions for students with past failures or outreach programs for those with high absences. Tracking how these interventions affect performance over time could be a way to test how effective the models are in practice.\n",
        "\n"
      ],
      "metadata": {
        "id": "bszAYEwu3eUa"
      }
    }
  ]
}